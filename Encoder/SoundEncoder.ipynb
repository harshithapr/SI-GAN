{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import urllib\n",
    "import zipfile\n",
    "import glob\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydub\n",
    "import librosa\n",
    "\n",
    "class Clip:\n",
    "    \"\"\"A single 5-sec long recording.\"\"\"\n",
    "    \n",
    "    RATE = 44100   # All recordings in ESC are 44.1 kHz\n",
    "    FRAME = 512    # Frame size in samples\n",
    "    \n",
    "    class Audio:\n",
    "        \"\"\"The actual audio data of the clip.\n",
    "        \n",
    "            Uses a context manager to load/unload the raw audio data. This way clips\n",
    "            can be processed sequentially with reasonable memory usage.\n",
    "        \"\"\"\n",
    "        \n",
    "        def __init__(self, path):\n",
    "            self.path = path\n",
    "        \n",
    "        def __enter__(self):\n",
    "            # Actual recordings are sometimes not frame accurate, so we trim/overlay to exactly 5 seconds\n",
    "            self.data = pydub.AudioSegment.silent(duration=5000)\n",
    "            self.data = self.data.overlay(pydub.AudioSegment.from_file(self.path)[0:5000])\n",
    "            self.raw = (np.fromstring(self.data._data, dtype=\"int16\") + 0.5) / (0x7FFF + 0.5)   # convert to float\n",
    "            return(self)\n",
    "        \n",
    "        def __exit__(self, exception_type, exception_value, traceback):\n",
    "            if exception_type is not None:\n",
    "                print(exception_type, exception_value, traceback)\n",
    "            del self.data\n",
    "            del self.raw\n",
    "        \n",
    "    def __init__(self, filename):\n",
    "        self.filename = os.path.basename(filename)\n",
    "        self.path = os.path.abspath(filename)        \n",
    "        self.directory = os.path.dirname(self.path)\n",
    "        self.category = self.directory.split('/')[-1]\n",
    "        \n",
    "        self.audio = Clip.Audio(self.path)\n",
    "        \n",
    "        with self.audio as audio:\n",
    "            self._compute_mfcc(audio)    \n",
    "            self._compute_zcr(audio)\n",
    "            \n",
    "    def _compute_mfcc(self, audio):\n",
    "        # MFCC computation with default settings (2048 FFT window length, 512 hop length, 128 bands)\n",
    "        self.melspectrogram = librosa.feature.melspectrogram(audio.raw, sr=Clip.RATE, hop_length=Clip.FRAME)\n",
    "        self.logamplitude = librosa.logamplitude(self.melspectrogram)\n",
    "        self.mfcc = librosa.feature.mfcc(S=self.logamplitude, n_mfcc=13).transpose()\n",
    "            \n",
    "    def _compute_zcr(self, audio):\n",
    "        # Zero-crossing rate\n",
    "        self.zcr = []\n",
    "        frames = int(np.ceil(len(audio.data) / 1000.0 * Clip.RATE / Clip.FRAME))\n",
    "        \n",
    "        for i in range(0, frames):\n",
    "            frame = Clip._get_frame(audio, i)\n",
    "            self.zcr.append(np.mean(0.5 * np.abs(np.diff(np.sign(frame)))))\n",
    "\n",
    "        self.zcr = np.asarray(self.zcr)\n",
    "            \n",
    "    @classmethod\n",
    "    def _get_frame(cls, audio, index):\n",
    "        if index < 0:\n",
    "            return None\n",
    "        return audio.raw[(index * Clip.FRAME):(index+1) * Clip.FRAME]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '<{0}/{1}>'.format(self.category, self.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "\n",
    "import seaborn as sb\n",
    "sb.set(style=\"white\", palette=\"muted\")\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ESC-10 recordings loaded.\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(name):\n",
    "    \"\"\"Load all dataset recordings into a nested list.\"\"\"\n",
    "    clips = []\n",
    "    \n",
    "    for directory in sorted(os.listdir('{0}/'.format(name))):\n",
    "        directory = '{0}/{1}'.format(name, directory)\n",
    "        if os.path.isdir(directory) and os.path.basename(directory)[0:3].isdigit():\n",
    "            print('Parsing ' + directory)\n",
    "            category = []\n",
    "            for clip in sorted(os.listdir(directory)):\n",
    "                if clip[-3:] == 'ogg':\n",
    "                    category.append(Clip('{0}/{1}'.format(directory, clip)))\n",
    "            clips.append(category)\n",
    "            \n",
    "    IPython.display.clear_output()\n",
    "    print('All {0} recordings loaded.'.format(name))            \n",
    "    \n",
    "    return clips\n",
    "\n",
    "clips_10 = load_dataset('ESC-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = 10\n",
    "clips_shown = 40\n",
    "Y_data = np.zeros((categories,clips_shown))\n",
    "for c in range(1, categories):\n",
    "    Y_data[c] =np.asarray([c]*clips_shown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_400 = np.array(clips_10).flatten()\n",
    "Y_data_400= Y_data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data_400.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can reload this cell to get a different clip at every try\n",
    "\n",
    "import random\n",
    "all_recordings = glob.glob('ESC-10/*/*.ogg')\n",
    "clip = Clip(all_recordings[random.randint(0, len(all_recordings) - 1)])    \n",
    "\n",
    "# with clip.audio as audio:\n",
    "#     plt.subplot(2, 1, 1)\n",
    "#     plt.title('{0} : {1}'.format(clip.category, clip.filename))\n",
    "#     plt.plot(np.arange(0, len(audio.raw)) / 44100.0, audio.raw)\n",
    "#     print(len(audio.raw))\n",
    "   \n",
    "#     plt.subplot(2, 1, 2)\n",
    "#     librosa.display.specshow(clip.logamplitude, sr=44100, x_axis='frames', y_axis='linear', cmap='RdBu_r')\n",
    "    \n",
    "# IPython.display.Audio(filename=clip.path, rate=Clip.RATE)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfcc_inp = []\n",
    "for recording in all_recordings:\n",
    "    clip = Clip(recording)\n",
    "    mfcc_inp.append(clip.mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mfcc_np2D = np.array(mfcc_inp)\n",
    "mfcc_np = mfcc_np2D.reshape(mfcc_np2D.shape[0],mfcc_np2D.shape[1],mfcc_np2D.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "# Add whatever you want\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#print \"TensorFlow Version {}\".format(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "    def __init__(self):\n",
    "        self.num_epoch = 5\n",
    "        self.batch_size = 128\n",
    "        self.log_step = 50\n",
    "        self._build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final Working Model with 70% accuracy\n",
    "class YourModel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super(YourModel, self).__init__()\n",
    "        self.num_epoch = 20\n",
    "        self.batch_size = 50\n",
    "    \n",
    "    # Define max pooling and conv layers\n",
    "    def conv2d(self, input, kernel_size, stride, num_filter):\n",
    "        stride_shape = [1, stride, stride, 1]\n",
    "        filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "        W = tf.get_variable('w', filter_shape, tf.float32, tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.get_variable('b', [1, 1, 1, num_filter], initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(W), 0.0, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "        \n",
    "        return tf.nn.conv2d(input, W, stride_shape, padding='SAME') + b\n",
    "\n",
    "    def max_pool(self, input, kernel_size, stride):\n",
    "        ksize = [1, kernel_size, kernel_size, 1]\n",
    "        strides = [1, stride, stride, 1]\n",
    "        return tf.nn.max_pool(input, ksize=ksize, strides=strides, padding='SAME')\n",
    "\n",
    "    #######################self######################################################\n",
    "    # TODO: You can add any layers (fully-connected, normalization)             #\n",
    "    #############################################################################\n",
    "    # def FC(input, out_neurons):\n",
    "    #     return tf.contrib.layers.fully_connected(input, out_neurons)\n",
    "    def FC(self, input, inp_neurons, out_neurons):\n",
    "        #W = tf.get_variable('w',[inp_neurons,out_neurons], tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "        W = tf.get_variable('w',[inp_neurons,out_neurons], tf.float32, tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.get_variable('b', [out_neurons], initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(W), 0.004, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "        \n",
    "        return tf.matmul(input, W) + b\n",
    "\n",
    "    def Normalization(self, input):\n",
    "        return tf.nn.local_response_normalization(input,\n",
    "                                                  alpha=0.001 / 9.0,\n",
    "                                                  beta=0.75,\n",
    "                                                  depth_radius=4,\n",
    "                                                  bias=1.0)\n",
    "\n",
    "    #############################################################################\n",
    "    #                             END OF YOUR CODE                              #\n",
    "    #############################################################################  \n",
    "    def _model(self):\n",
    "        print('-' * 5 + '  Sample model  ' + '-' * 5)\n",
    "\n",
    "        print('intput layer: ' + str(self.X.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv1'):\n",
    "            self.conv1 = self.conv2d(self.X, 3, 1, 4)\n",
    "            self.relu1 = tf.nn.relu(self.conv1)\n",
    "            #self.lnorm1 = self.Normalization(self.relu1)\n",
    "            #self.pool1 = self.max_pool(self.lnorm1, 2, 2)            \n",
    "            print('conv1 layer: ' + str(self.relu1.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv2'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.conv2 = self.conv2d(self.relu1, 3, 1, 8)\n",
    "            self.relu2 = tf.nn.relu(self.conv2)\n",
    "            #self.lnorm2 = self.Normalization(self.relu2)\n",
    "            #self.pool2 = self.max_pool(self.lnorm2, 2, 2)            \n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('conv2 layer: ' + str(self.relu2.get_shape()))\n",
    "\n",
    "\n",
    "        with tf.variable_scope('conv3'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.conv3 = self.conv2d(self.relu2, 3, 1, 16)\n",
    "            self.relu3 = tf.nn.relu(self.conv3)\n",
    "#             self.lnorm3 = self.Normalization(self.relu3)\n",
    "#             self.pool3 = self.max_pool(self.lnorm3, 2, 2)   \n",
    "\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('conv3 layer: ' + str(self.relu3.get_shape()))\n",
    "            \n",
    "        with tf.variable_scope('conv4'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.conv4 = self.conv2d(self.relu3, 3, 1, 16)\n",
    "            self.relu4 = tf.nn.relu(self.conv4)\n",
    "#             self.lnorm3 = self.Normalization(self.relu3)\n",
    "#             self.pool3 = self.max_pool(self.lnorm3, 2, 2)   \n",
    "\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('conv4 layer: ' + str(self.relu4.get_shape()))   \n",
    "        \n",
    "        #############################################################################\n",
    "        # TODO: Flatten the output tensor from conv2 layer                          #\n",
    "        #############################################################################\n",
    "        self.flat = tf.contrib.layers.flatten(self.relu4)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                           #\n",
    "        #############################################################################      \n",
    "        print('flat layer: ' + str(self.flat.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('fc5'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc5 = self.FC(self.flat, self.flat.get_shape()[1], 1024)\n",
    "            self.relu5 = tf.nn.relu(self.fc5)\n",
    "            if self.is_train:\n",
    "                self.drop_out5 = tf.nn.dropout(self.relu5, self.keep_prob_fc5)\n",
    "            else:\n",
    "                self.drop_out5 = self.relu5\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc5 layer: ' + str(self.drop_out5.get_shape()))\n",
    "            \n",
    "        \n",
    "        with tf.variable_scope('fc6'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc6 = self.FC(self.drop_out5, self.drop_out5.get_shape()[1], 128)\n",
    "            self.relu6 = tf.nn.relu(self.fc6)\n",
    "            if self.is_train:\n",
    "                self.drop_out6 = tf.nn.dropout(self.relu6, self.keep_prob_fc6)\n",
    "            else:\n",
    "                self.drop_out6 = self.relu6\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc6 layer: ' + str(self.drop_out6.get_shape()))\n",
    "        \n",
    "\n",
    "        with tf.variable_scope('fc7'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc7 = self.FC(self.drop_out6, self.drop_out6.get_shape()[1], 10)            \n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc7 layer: ' + str(self.fc7.get_shape()))\n",
    "        \n",
    "        # Return the last layer\n",
    "        return self.fc7\n",
    "\n",
    "    def _input_ops(self):\n",
    "        # Placeholders\n",
    "        self.X = tf.placeholder(tf.float32, [None, 431, 13, 1])\n",
    "        self.Y = tf.placeholder(tf.int64, [None])\n",
    "        \n",
    "        #############################################################################\n",
    "        # TODO: You can add any placeholders                                        #\n",
    "        #############################################################################\n",
    "        self.is_train = True\n",
    "        self.keep_prob_fc5 = tf.placeholder(tf.float32)\n",
    "        self.keep_prob_fc6 = tf.placeholder(tf.float32)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        # Adam optimizer 'self.train_op' that minimizes 'self.loss_op'\n",
    "        #############################################################################\n",
    "        # TODO: Complete the following functions                                    #\n",
    "        #############################################################################\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.initial_lr = 1e-3\n",
    "        #self.exp_decay = tf.train.exponential_decay(self.initial_lr, self.global_step, 500, 0.96)\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate=self.initial_lr).minimize(self.loss_op, global_step=self.global_step)\n",
    "\n",
    "        \n",
    "    def _loss(self, labels, logits):\n",
    "        # Softmax cross entropy loss 'self.loss_op'\n",
    "        #############################################################################\n",
    "        # TODO: Complete the following functions                                    #\n",
    "        #############################################################################\n",
    "       \n",
    "        cross_entropy_mean = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits))     \n",
    "        tf.add_to_collection('losses', cross_entropy_mean)\n",
    "        self.loss_op = tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Define input variables\n",
    "        self._input_ops()\n",
    "\n",
    "        # Convert Y to one-hot vector\n",
    "        labels = tf.one_hot(self.Y, 10)\n",
    "\n",
    "        # Build a model and get logits\n",
    "        logits = self._model()\n",
    "\n",
    "        # Compute loss\n",
    "        self._loss(labels, logits)\n",
    "        \n",
    "        # Build optimizer\n",
    "        self._build_optimizer()\n",
    "\n",
    "        # Compute accuracy\n",
    "        predict = tf.argmax(logits, 1)\n",
    "        correct = tf.equal(predict, self.Y)\n",
    "        self.accuracy_op = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        \n",
    "    def train(self, sess, X_train, Y_train, X_val, Y_val):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        step = 0\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        print('-' * 5 + '  Start training  ' + '-' * 5)\n",
    "        \n",
    "        self.is_train = True\n",
    "        for epoch in range(self.num_epoch):\n",
    "            print('train for epoch %d' % epoch)\n",
    "            for i in range(num_training // self.batch_size):\n",
    "                X_ = X_train[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "                Y_ = Y_train[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\n",
    "                #############################################################################\n",
    "                # TODO: You can change feed data as you want                                #\n",
    "                #############################################################################\n",
    "                feed_dict = {self.X: X_, self.Y:Y_, self.keep_prob_fc5: 0.7, self.keep_prob_fc6: 0.8}                \n",
    "                fetches = [self.train_op, self.loss_op, self.accuracy_op]\n",
    "\n",
    "                _, loss, accuracy = sess.run(fetches, feed_dict=feed_dict)\n",
    "                losses.append(loss)\n",
    "                accuracies.append(accuracy)\n",
    "                if step % self.log_step == 0:\n",
    "                    print('iteration (%d): loss = %.3f, accuracy = %.3f' %\n",
    "                        (step, loss, accuracy))\n",
    "                step += 1\n",
    "\n",
    "            #############################################################################\n",
    "            # TODO: Plot training curves                                                #\n",
    "            #############################################################################\n",
    "            # Graph 1. X: epoch, Y: training loss\n",
    "\n",
    "            # Graph 2. X: epoch, Y: training accuracy\n",
    "            \n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "\n",
    "            # Print validation results\n",
    "            self.is_train = False\n",
    "            print('validation for epoch %d' % epoch)\n",
    "            val_accuracy = self.evaluate(sess, X_val, Y_val)\n",
    "            print('-  epoch %d: validation accuracy = %.3f' % (epoch, val_accuracy))\n",
    "            self.is_train = True\n",
    "\n",
    "    def evaluate(self, sess, X_eval, Y_eval):\n",
    "        eval_accuracy = 0.0\n",
    "        eval_iter = 0\n",
    "        for i in range(X_eval.shape[0] // self.batch_size):\n",
    "            X_ = X_eval[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "            Y_ = Y_eval[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\n",
    "            feed_dict = {self.X:X_, self.Y:Y_, self.keep_prob_fc5: 0.7, self.keep_prob_fc6: 0.8}  \n",
    "            accuracy = sess.run(self.accuracy_op, feed_dict=feed_dict)\n",
    "            eval_accuracy += accuracy\n",
    "            eval_iter += 1\n",
    "        return eval_accuracy / eval_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Sample model  -----\n",
      "intput layer: (?, 431, 13, 1)\n",
      "conv1 layer: (?, 431, 13, 4)\n",
      "conv2 layer: (?, 431, 13, 8)\n",
      "conv3 layer: (?, 431, 13, 16)\n",
      "conv4 layer: (?, 431, 13, 16)\n",
      "flat layer: (?, 89648)\n",
      "fc5 layer: (?, 1024)\n",
      "fc6 layer: (?, 128)\n",
      "fc7 layer: (?, 10)\n",
      "-----  Start training  -----\n",
      "train for epoch 0\n",
      "iteration (0): loss = 9.155, accuracy = 0.300\n",
      "validation for epoch 0\n",
      "-  epoch 0: validation accuracy = 0.040\n",
      "train for epoch 1\n",
      "validation for epoch 1\n",
      "-  epoch 1: validation accuracy = 0.000\n",
      "train for epoch 2\n",
      "validation for epoch 2\n",
      "-  epoch 2: validation accuracy = 0.020\n",
      "train for epoch 3\n",
      "validation for epoch 3\n",
      "-  epoch 3: validation accuracy = 0.040\n",
      "train for epoch 4\n",
      "validation for epoch 4\n",
      "-  epoch 4: validation accuracy = 0.080\n",
      "train for epoch 5\n",
      "validation for epoch 5\n",
      "-  epoch 5: validation accuracy = 0.080\n",
      "train for epoch 6\n",
      "validation for epoch 6\n",
      "-  epoch 6: validation accuracy = 0.100\n",
      "train for epoch 7\n",
      "validation for epoch 7\n",
      "-  epoch 7: validation accuracy = 0.060\n",
      "train for epoch 8\n",
      "iteration (50): loss = 6.767, accuracy = 0.480\n",
      "validation for epoch 8\n",
      "-  epoch 8: validation accuracy = 0.160\n",
      "train for epoch 9\n",
      "validation for epoch 9\n",
      "-  epoch 9: validation accuracy = 0.100\n",
      "train for epoch 10\n",
      "validation for epoch 10\n",
      "-  epoch 10: validation accuracy = 0.080\n",
      "train for epoch 11\n",
      "validation for epoch 11\n",
      "-  epoch 11: validation accuracy = 0.140\n",
      "train for epoch 12\n",
      "validation for epoch 12\n",
      "-  epoch 12: validation accuracy = 0.100\n",
      "train for epoch 13\n",
      "validation for epoch 13\n",
      "-  epoch 13: validation accuracy = 0.060\n",
      "train for epoch 14\n",
      "validation for epoch 14\n",
      "-  epoch 14: validation accuracy = 0.120\n",
      "train for epoch 15\n",
      "validation for epoch 15\n",
      "-  epoch 15: validation accuracy = 0.120\n",
      "train for epoch 16\n",
      "iteration (100): loss = 4.280, accuracy = 0.940\n",
      "validation for epoch 16\n",
      "-  epoch 16: validation accuracy = 0.200\n",
      "train for epoch 17\n",
      "validation for epoch 17\n",
      "-  epoch 17: validation accuracy = 0.160\n",
      "train for epoch 18\n",
      "validation for epoch 18\n",
      "-  epoch 18: validation accuracy = 0.120\n",
      "train for epoch 19\n",
      "validation for epoch 19\n",
      "-  epoch 19: validation accuracy = 0.160\n",
      "***** test accuracy: 0.000\n",
      "Model saved in ./S2I.ckpt\n"
     ]
    }
   ],
   "source": [
    "num_training = 300\n",
    "num_validation = 50\n",
    "num_test = 50\n",
    "# Clear old computation graphs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#############################################################################\n",
    "# TODO: Preprocessing                                                       #\n",
    "#############################################################################\n",
    "X_train_ = mfcc_np[:300]\n",
    "X_val_ = mfcc_np[300:350]\n",
    "X_test_ = mfcc_np[350:400]\n",
    "\n",
    "Y_train = Y_data_400[:300]\n",
    "Y_val = Y_data_400[300:350]\n",
    "Y_test = Y_data_400[350:400]\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "\n",
    "model = YourModel()\n",
    "model.train(sess, X_train_, Y_train, X_val_, Y_val)\n",
    "model.is_train = False\n",
    "accuracy = model.evaluate(sess, X_test_, Y_test)\n",
    "print('***** test accuracy: %.3f' % accuracy)\n",
    "\n",
    "# Save your model\n",
    "saver = tf.train.Saver()\n",
    "model_path = saver.save(sess, \"./S2I.ckpt\")\n",
    "print(\"Model saved in %s\" % model_path)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
